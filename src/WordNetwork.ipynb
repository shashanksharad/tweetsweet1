{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY-L1lvlcUTX"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus of 6 billion words\n",
        "dim=50) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLXmV5D0W9fL",
        "outputId": "6d7fd3a3-840b-4c13-c734-9ba59b31dc36"
      },
      "source": [
        "def word_vec(word):\n",
        "  return glove[word]\n",
        "\n",
        "def cosine_sim(vector_1, vector_2):\n",
        "  return torch.cosine_similarity(vector_1.unsqueeze(0), vector_2.unsqueeze(0))\n",
        "\n",
        "\n",
        "def simmilarity(word1, word2):\n",
        "  return cosine_sim(word_vec(word1), word_vec(word2))\n",
        "\n",
        "simmilarity('nigga', 'nigro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1597])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49zchVD9d-h5",
        "outputId": "bfc7fd5c-a300-45d1-a3af-a7cfdd7b9901"
      },
      "source": [
        "word_vec(\"shit\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-6.1396e-01,  1.7478e-01,  5.7008e-02, -1.6326e+00,  1.5258e-01,\n",
              "        -7.5744e-01,  1.7240e-01, -3.0148e-01,  2.7009e-02,  1.6019e+00,\n",
              "        -7.0764e-01,  6.8023e-01,  2.2553e-01,  1.0254e+00,  1.6152e-01,\n",
              "         1.4885e-01,  8.8233e-01, -8.6374e-03, -1.4107e-03,  1.1392e+00,\n",
              "        -7.0934e-01, -3.1530e-01,  1.6758e+00,  4.1512e-01,  6.7164e-01,\n",
              "        -6.3516e-01, -1.5862e+00,  8.7716e-01,  1.0955e+00, -9.2124e-01,\n",
              "         3.5458e-01,  1.2302e-01,  1.2504e-02,  1.6347e+00, -2.8170e-02,\n",
              "        -5.4797e-02,  6.9939e-01, -7.9258e-02,  1.0559e-01,  2.1636e-01,\n",
              "        -3.5064e-01, -1.9988e-01, -8.4036e-01,  6.9721e-01,  6.6648e-01,\n",
              "        -2.0986e-01, -6.5187e-02, -1.5728e-01,  4.3393e-01,  3.0487e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieUIUBS9le_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c25b0f2-b6a4-483a-faee-7e2df0a2dd5a"
      },
      "source": [
        "tweets = ['@444keni ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚', 'Just say Rip to that man and keep it moving', 'The hate Virgil got was just niggas being weird anâ€¦pinions, you canâ€™t please everybody and thatâ€™s ok', 'This year is draining all of us hoping for the best https://t.co/IwDk4ql0RH', 'Chukwu chebe anyi niile', 'Virgil showed young niggas allover the world this shit possible Rest In Peace', 'VIRGIL IS DEAD WHAT IN THE FUCK ??', 'If you extra ugly Iâ€™ll give you 600 on god', 'Sending all ugly mfs 200 dollars where yâ€™all at', '@notaprilfr I swear I do LMAOOO', 'RT @notaprilfr: @DAMAGEDTROOP410 we need u to say you love violence and confusion again', '@doogiehowsergte Nigga what you do ðŸ˜‚ðŸ˜‚ ??', 'I canâ€™t live foreverrrrr I know someday I gotta leâ€¦inging his heart out lmao https://t.co/N7YrlOSfOg', 'Itâ€™s called Donâ€™t matter https://t.co/7g2dDEYCbD', 'That bar was random as shit but bro obviously had to get it off his chest lmao', 'When youngboy said â€œMy lil cousin they African so â€¦t me with that racist shitâ€ I felt that he get it', 'I love my life so much that I donâ€™t want any fuck niggas in it', '@CyberRuntz Itâ€™s life changing fr', 'RT @CyberRuntz: @DAMAGEDTROOP410 put me on to fufu and my life been different ever since ðŸ¤', '@natenumbaeight LMAOOO', '@kimmythegod LMAOOO', 'RT @flvmeprincesss: in the words of @DAMAGEDTROOP410  these pussy niggas not feelin me', 'Nigga said he be putting acid in his dog treats lmaooo', 'RT @NicoStillSFS: This the funniest space ever bruh @DAMAGEDTROOP410', 'Get on this bitch and whisper https://t.co/zGWI6h5l3t', 'Imagine still recovering from genocide that happenâ€¦just to see a whole other race claiming to be you', 'I know indigenous people be so upset when they see niggas calling themselves native Americans', '@promise_akubue You speak Igbo lmao ?', 'When Iâ€™m dead my niggas gotta say stupid shit like this about me https://t.co/KiPOk4xKE5', 'I kinda like this nigga https://t.co/EVSv3CVcYl', 'You canâ€™t please everybody fuck these niggas', 'I feel like a new man itâ€™s still hope for me', 'I really went to sleep at 9PM for the 1st time in like 13 years and actually stayed sleep', 'Before you speak on a nigga you donâ€™t know ask yourself â€œis dick riding this important to meâ€', 'RT @tayyv: this the realest nigga on twitter ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­', 'RT @chrollo_lord: When that jerk sauce hit the the back of ya throat https://t.co/iDfY0TwbOi', 'Jamaicans cooking Mac and cheese everybody RUN!!', 'She on her own time ðŸ˜‚ðŸ˜‚ https://t.co/vsPVgT01dG', '@anadeldank ðŸ˜‚ðŸ˜‚ðŸ˜‚ she not rushing for nobody', 'RT @anadeldank: Im your mom ðŸ˜‚ðŸ˜‚ðŸ˜‚', 'My mother just putting the turkey in at 4PM LMAO she ghetto as shit', 'LMAOOOOOO https://t.co/WGvfLPW116', 'What white people be eating for thanksgiving, green eggs and ham ??', 'RIP my father and free my brother', 'Nigga got seaweed on his plate https://t.co/FAwTPxbwRL', 'RT @chuychvzz: realest shit ive heard all year', 'So thankful Iâ€™m nothing like these niggas', 'Fuck thanksgiving ðŸ’¯', 'A Puerto Rican Muslim is insane', 'RT @luvsxka: This man @DAMAGEDTROOP410 be talkin his shit but people donâ€™t wanna listen', 'I didnâ€™t know niggas could get this stupid until I started getting on Twitter', '@caassshhhhh I thought you was from Egypt', 'I was 6 blunts in fighting for my life ngl https://t.co/UaD4wDPujg', 'RT @staxhigh_swiggs: @stormiji only @DAMAGEDTROOP4â€¦being the voice of reason https://t.co/MwrIecvCc0', '@slaymsav That conversation was making my brain rot oh my god lmaooo', 'Ima keep talking my shit I fear https://t.co/2VOWlsKIDv', 'RT @lajjsabat: I know what your saying please keep speaking bro @DAMAGEDTROOP410', 'But I get it tho common sense isnâ€™t common and nigâ€¦hate themselves so shit will never be that simple', 'White people fucked us up so bad as a whole niggasâ€¦h different experiences, Itâ€™s just that simple...', 'Iâ€™m surprised these niggas not pregnant smh https://t.co/W2DLuaeTqw', 'RT @444guap: niggas on my dick at 3 am, crazy - @DAMAGEDTROOP410', 'RT @buwi6: @DAMAGEDTROOP410 pls ily keep going ðŸ’€', 'I literally run a business I know where Iâ€™m going â€¦\\uDE02 https://t.co/1Fm4OM4UUz https://t.co/u2geMpDCNI', 'Anti black girl from the suburbs you sound like a white woman LMAO https://t.co/ePLy8rLOcW', '- A nigga that think Africa a country LMAO https://t.co/uQCLxoNo6F', '@gtedoogie Nigga that space was insaneðŸ˜‚', '@slaymsav ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚', '@slaymsav What happen I just woke up', 'You Scottish niggas insane LMAOOO https://t.co/9qilh0e6dC', 'RT @notscoeuros: @DAMAGEDTROOP410 is cool as fuck', 'Yo wtf going on LMAOOO  https://t.co/V3TzfNH9Ue', 'Yo wtf going on LMAOOOO', 'LMAOOO https://t.co/siaq4yb0q1', '@XAVALEXANDER I might gotta do that', 'RT @XAVALEXANDER: make that 757 popup event happen', 'Who got some cows and pigs for sale tap in letâ€™s get rich', 'About to go to Virginia for no reason', 'Bitch got the name Larry tatted on her face ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚', 'She just took this dick wayyy back Iâ€™m buying a saxophone tomorrow I fear', 'Just got some head to some Jazz music she sucked that dick back into the 60â€™s', 'During the transatlantic slave trade enslaved Afriâ€¦ white niggas was hating hard when they seen that', 'She donâ€™t deserve kids I hate this bitch', 'And the dumb bitch in the back comparing skin toneâ€¦ Iâ€™m going back to Africa https://t.co/O7IuG2qiNo', 'Nigga 15 https://t.co/K8pFKYMa56', 'RT @StonedDaniel: I wonder - Kanye West', 'You ever bump a song that make you feel good to be alive', 'He said â€œDamn my niggaâ€ https://t.co/SOKmApT4px', 'Had the gun to that nigga chest and farted https://t.co/YY56Fqmcoh', '@419kiddd Lmaooo', 'Shit was so intense', 'I remember in 2015 I was hitting a lick and I farted', '@natenumbaeight You just like me', 'You better get the fuck outta my face', 'Wish I would let a bitch with some cards tell me about myself', '@valoravee LMAOOOOO', '@RIPSCHICAGO Niggas be Delusional LMAOOO', 'Shordy said niggas wouldnâ€™t survive in the UK bitch Ima Nigerian from Baltimore LMAOO']\n",
        "\n",
        "tx_scores = [0, 0.134, 1, 0.001, 0.025, 1, 0.999, 0.96, 1, 0.003, 0.011, 0.998, 0.999, 0, 1, 1, 1, 0, 0.18, 0, 0, 1, 0.999, 0, 1, 0.546, 0.999, 0.021, 1, 0.999, 1, 0, 0, 1, 0.999, 0.959, 0.001, 0, 0.005, 0.039, 1, 0.001, 0.002, 0.001, 0.934, 1, 1, 1, 0.999, 1, 1, 0, 0.386, 0, 0.767, 1, 0, 1, 1, 1, 1, 0, 0, 0.99, 1, 0.999, 0, 0, 1, 1, 0.013, 0.019, 0, 0, 0, 0.001, 0, 1, 1, 0.993, 1, 1, 1, 0.959, 0, 0.001, 1, 1, 0, 0.062, 0.001, 0, 1, 1, 0, 0.998, 1]\n",
        "tx_class = [1 if tx_scores[i]>=0.5 else 0 for i in range(len(tx_scores))]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXI5sgFNfMB8",
        "outputId": "a3923ff8-84a8-4254-ec7f-6da60819fe3b"
      },
      "source": [
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "\n",
        "\n",
        "all_words_tx = []\n",
        "all_words_ntx = []\n",
        "for cls, sen in zip(tx_class, tweets):\n",
        "  # print(cls)\n",
        "  # print(sen)\n",
        "  sen = re.sub(r\"http\\S+\", \"\", sen)\n",
        "  sen = deEmojify(sen)\n",
        "  # print(sen)\n",
        "  tokens = word_tokenize(sen)\n",
        "  # convert to lower case\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  # remove punctuation from each word\n",
        " \n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  # filter out stop words\n",
        "  \n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  if cls==1:\n",
        "    all_words_tx += [w for w in words if not w in stop_words and not w in ['rt'] and w in glove.itos]\n",
        "  else:\n",
        "    all_words_ntx += [w for w in words if not w in stop_words and not w in ['rt'] and w in glove.itos]\n",
        "\n",
        "\n",
        "n_words = 30 #total number of words to be shown in the graph\n",
        "n_tx_words = len(set(all_words_tx))\n",
        "n_ntx_words = len(set(all_words_ntx))\n",
        "\n",
        "n_top_tx_words = 0 #number of words to be shown from toxic class\n",
        "n_top_ntx_words = 0 #number of words to be shown from nontoxic class\n",
        "\n",
        "if n_tx_words < n_words*0.5 and n_ntx_words > n_words*0.5:\n",
        "  n_top_tx_words = n_tx_words\n",
        "  n_top_ntx_words = int(n_words-n_tx_words)\n",
        "\n",
        "if n_tx_words > n_words*0.5 and n_ntx_words < n_words*0.5:\n",
        "  n_top_ntx_words = n_ntx_words\n",
        "  n_top_tx_words = int(n_words-n_ntx_words)\n",
        "\n",
        "if n_tx_words < n_words*0.5 and n_ntx_words < n_words*0.5:\n",
        "  n_top_ntx_words = n_ntx_words\n",
        "  n_top_tx_words = n_tx_words\n",
        "\n",
        "if n_tx_words > n_words*0.5 and n_ntx_words > n_words*0.5:\n",
        "  n_top_ntx_words = int(0.5*n_words)\n",
        "  n_top_tx_words = int(0.5*n_words)\n",
        "\n",
        "print(n_top_ntx_words, n_top_tx_words)\n",
        "\n",
        "\n",
        "tx_words, ntx_words = Counter(all_words_tx).most_common(n_top_tx_words), Counter(all_words_ntx).most_common(n_top_ntx_words)\n",
        "tx_words = [t[0] for t in tx_words]\n",
        "ntx_words = [t[0] for t in ntx_words]\n",
        "print(tx_words)\n",
        "print(ntx_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "15 15\n",
            "['niggas', 'nigga', 'shit', 'got', 'fuck', 'get', 'bitch', 'back', 'know', 'said', 'like', 'dick', 'virgil', 'people', 'insane']\n",
            "['going', 'keep', 'life', 'ever', 'like', 'say', 'rip', 'man', 'feel', 'sleep', 'time', 'run', 'reason', 'know', 'happen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCHEYiPhu9D"
      },
      "source": [
        "all_words = list(set(tx_words+ntx_words))\n",
        "sim = np.zeros((len(all_words), len(all_words)))\n",
        "for i, w in enumerate(all_words):\n",
        "  for j, w_ in enumerate(all_words):\n",
        "    sim[i, j] = simmilarity(w, w_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWIX3JUEm5CV"
      },
      "source": [
        "def make_set(lst_tpls):\n",
        "  d0, d1 = {item[0] for item in lst_tpls}, {item[1] for item in lst_tpls}\n",
        "  d_all = d1.union(d0)\n",
        "  return list(d_all)\n",
        "\n",
        "thrsh = 0.5\n",
        "l = list(zip(list(np.where(sim>thrsh)[0]), list(np.where(sim>thrsh)[1]))) #list of word index tuples\n",
        "l = list({tuple(sorted(item)) for item in l}) #remove reversed duplicates e.g. (1,2) and (2,1)\n",
        "l = [(l_[0], l_[1]) for l_ in l if l_[0]!=l_[1]]\n",
        "\n",
        "uniq_wrd_ids = make_set(l)\n",
        "uniq_wrds = [all_words[uniq_wrd_ids[i]] for i in range(len(uniq_wrd_ids))]\n",
        "df = pd.DataFrame(uniq_wrds, columns = [\"word\"])\n",
        "df.to_csv('all_words.csv', index = False)\n",
        "\n",
        "sim_wrds = [[all_words[l[i][0]], all_words[l[i][1]], sim[l[i][0], l[i][1]]] for i in range(len(l))]\n",
        "df = pd.DataFrame(sim_wrds, columns=[\"source\", \"target\", \"similarity\"])\n",
        "df.head(100)\n",
        "df.to_csv('word_nerwork.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3150n1qEM-zD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}